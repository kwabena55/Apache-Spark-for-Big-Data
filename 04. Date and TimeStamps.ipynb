{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date and TimeStamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.1.1.tar.gz (212.3 MB)\n",
      "Collecting py4j==0.10.9\n",
      "  Using cached py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): still running...\n",
      "  Building wheel for pyspark (setup.py): still running...\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767609 sha256=b6de65dba7cc00c4f85831bd39765a50ce14beb28571dda61db5281e24ad713c\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\b3\\0e\\81\\264aeed961e43b9f6ba9ec81c8c540d2d7dccc52c6b51cbf22\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.1\n",
      "Collecting pyspark\n",
      "  Using cached pyspark-3.1.1.tar.gz (212.3 MB)\n",
      "Collecting py4j==0.10.9\n",
      "  Using cached py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): still running...\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767609 sha256=34b495790746af3430bd5101fb544559778809f1cb5d3a7ec3720a644a3abc2a\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\b3\\0e\\81\\264aeed961e43b9f6ba9ec81c8c540d2d7dccc52c6b51cbf22\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"Datetime\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"C:/Users/User/Desktop/Data/appl_stock.csv\", header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "|      Date|      Open|      High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|213.429998|214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|214.599998|215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|214.379993|    215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|    211.75|212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|210.299994|212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2010-01-04', Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039),\n",
       " Row(Date='2010-01-05', Open=214.599998, High=215.589994, Low=213.249994, Close=214.379993, Volume=150476200, Adj Close=27.774976000000002)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date='2010-01-04', Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Date|      Open|\n",
      "+----------+----------+\n",
      "|2010-01-04|213.429998|\n",
      "|2010-01-05|214.599998|\n",
      "|2010-01-06|214.379993|\n",
      "|2010-01-07|    211.75|\n",
      "|2010-01-08|210.299994|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"Date\",\"Open\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (dayofmonth,\\\n",
    "                                   dayofweek,\\\n",
    "                                   dayofyear,\\\n",
    "                                   month,\\\n",
    "                                   year,\\\n",
    "                                  format_number,\\\n",
    "                                  date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+----------+----------+--------+------------------+\n",
      "|      Date|              Open|              High|       Low|     Close|  Volume|         Adj Close|\n",
      "+----------+------------------+------------------+----------+----------+--------+------------------+\n",
      "|2016-12-30|        116.650002|        117.199997|    115.43|    115.82|30586300|         115.32002|\n",
      "|2016-12-29|        116.449997|        117.110001|116.400002|116.730003|15039500|        116.226096|\n",
      "|2016-12-28|        117.519997|        118.019997|116.199997|116.760002|20905900|116.25596499999999|\n",
      "|2016-12-27|        116.519997|        117.800003|116.489998|117.260002|18296900|116.75380600000001|\n",
      "|2016-12-23|        115.589996|        116.519997|115.589996|116.519997|14249500|        116.016995|\n",
      "|2016-12-22|        116.349998|        116.510002|115.639999|116.290001|26085900|        115.787993|\n",
      "|2016-12-21|        116.800003|        117.400002|116.779999|117.059998|23783200|116.55466499999999|\n",
      "|2016-12-20|        116.739998|             117.5|    116.68|116.949997|21425000|116.44513899999998|\n",
      "|2016-12-19|        115.800003|        117.379997|    115.75|116.639999|27779400|         116.13648|\n",
      "|2016-12-16|        116.470001|             116.5|115.650002|115.970001|44351100|        115.469374|\n",
      "|2016-12-15|        115.379997|        116.730003|115.230003|    115.82|46524500|         115.32002|\n",
      "|2016-12-14|        115.040001|        116.199997|114.980003|115.190002|34031800|        114.692743|\n",
      "|2016-12-13|        113.839996|115.91999799999999|    113.75|115.190002|43733800|        114.692743|\n",
      "|2016-12-12|        113.290001|             115.0|112.489998|113.300003|26374400|        112.810902|\n",
      "|2016-12-09|        112.309998|        114.699997|112.309998|113.949997|34402600|113.45808999999998|\n",
      "|2016-12-08|        110.860001|            112.43|110.599998|112.120003|27068300|111.63599599999999|\n",
      "|2016-12-07|        109.260002|        111.190002|109.160004|111.029999|29998700|        110.550697|\n",
      "|2016-12-06|             109.5|        110.360001|109.190002|109.949997|26195500|109.47535800000001|\n",
      "|2016-12-05|             110.0|        110.029999|    108.25|109.110001|34324500|108.63898700000001|\n",
      "|2016-12-02|109.16999799999999|        110.089996|108.849998|109.900002|26528000|        109.425578|\n",
      "+----------+------------------+------------------+----------+----------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df[\"Date\"].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------------+\n",
      "|Year|DayofWeek|              Open|\n",
      "+----+---------+------------------+\n",
      "|2016|        6|        116.650002|\n",
      "|2016|        5|        116.449997|\n",
      "|2016|        4|        117.519997|\n",
      "|2016|        3|        116.519997|\n",
      "|2016|        6|        115.589996|\n",
      "|2016|        5|        116.349998|\n",
      "|2016|        4|        116.800003|\n",
      "|2016|        3|        116.739998|\n",
      "|2016|        2|        115.800003|\n",
      "|2016|        6|        116.470001|\n",
      "|2016|        5|        115.379997|\n",
      "|2016|        4|        115.040001|\n",
      "|2016|        3|        113.839996|\n",
      "|2016|        2|        113.290001|\n",
      "|2016|        6|        112.309998|\n",
      "|2016|        5|        110.860001|\n",
      "|2016|        4|        109.260002|\n",
      "|2016|        3|             109.5|\n",
      "|2016|        2|             110.0|\n",
      "|2016|        6|109.16999799999999|\n",
      "+----+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df[\"Date\"].desc()).select(year(\"Date\").alias(\"Year\"),dayofweek(\"Date\").alias(\"DayofWeek\"),\"Open\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
