{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Read data File and Create Data Schema"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "spark=SparkSession.builder.appName(\"Data Processing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"C:/Users/User/Desktop/SparkFolder/Data/raw-flight-data.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n+----------+---------+-------+---------------+-------------+--------+--------+\n|        19|        5|     DL|          11433|        13303|      -3|       1|\n|        19|        5|     DL|          14869|        12478|       0|      -8|\n|        19|        5|     DL|          14057|        14869|      -4|     -15|\n|        19|        5|     DL|          15016|        11433|      28|      24|\n|        19|        5|     DL|          11193|        12892|      -6|     -11|\n|        19|        5|     DL|          10397|        15016|      -1|     -19|\n|        19|        5|     DL|          15016|        10397|       0|      -1|\n|        19|        5|     DL|          10397|        14869|      15|      24|\n|        19|        5|     DL|          10397|        10423|      33|      34|\n|        19|        5|     DL|          11278|        10397|     323|     322|\n|        19|        5|     DL|          14107|        13487|      -7|     -13|\n|        19|        5|     DL|          11433|        11298|      22|      41|\n|        19|        5|     DL|          11298|        11433|      40|      20|\n|        19|        5|     DL|          11433|        12892|      -2|      -7|\n|        19|        5|     DL|          10397|        12451|      71|      75|\n|        19|        5|     DL|          12451|        10397|      75|      57|\n|        19|        5|     DL|          12953|        10397|      -1|      10|\n|        19|        5|     DL|          11433|        12953|      -3|     -10|\n|        19|        5|     DL|          10397|        14771|      31|      38|\n|        19|        5|     DL|          13204|        10397|       8|      25|\n+----------+---------+-------+---------------+-------------+--------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- DayofMonth: integer (nullable = true)\n |-- DayOfWeek: integer (nullable = true)\n |-- Carrier: string (nullable = true)\n |-- OriginAirportID: integer (nullable = true)\n |-- DestAirportID: integer (nullable = true)\n |-- DepDelay: integer (nullable = true)\n |-- ArrDelay: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "source": [
    "Redefine Schema for Flights"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "flightschema=StructType([\n",
    "\n",
    "                            StructField(\"DayofMonth\",IntegerType(), False),\n",
    "                            StructField(\"DayOfWeek\",IntegerType(), False),\n",
    "                            StructField(\"Carrier\",StringType(), False),\n",
    "                            StructField(\"OriginAirportID\",IntegerType(), False),\n",
    "                            StructField(\"DestAirportID\",IntegerType(), False),\n",
    "                            StructField(\"DepDelay\",IntegerType(), False),\n",
    "                            StructField(\"ArrDelay\",IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv(\"C:/Users/User/Desktop/SparkFolder/Data/raw-flight-data.csv\",schema=flightschema,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n+----------+---------+-------+---------------+-------------+--------+--------+\n|        19|        5|     DL|          11433|        13303|      -3|       1|\n|        19|        5|     DL|          14869|        12478|       0|      -8|\n|        19|        5|     DL|          14057|        14869|      -4|     -15|\n|        19|        5|     DL|          15016|        11433|      28|      24|\n|        19|        5|     DL|          11193|        12892|      -6|     -11|\n|        19|        5|     DL|          10397|        15016|      -1|     -19|\n|        19|        5|     DL|          15016|        10397|       0|      -1|\n|        19|        5|     DL|          10397|        14869|      15|      24|\n|        19|        5|     DL|          10397|        10423|      33|      34|\n|        19|        5|     DL|          11278|        10397|     323|     322|\n|        19|        5|     DL|          14107|        13487|      -7|     -13|\n|        19|        5|     DL|          11433|        11298|      22|      41|\n|        19|        5|     DL|          11298|        11433|      40|      20|\n|        19|        5|     DL|          11433|        12892|      -2|      -7|\n|        19|        5|     DL|          10397|        12451|      71|      75|\n|        19|        5|     DL|          12451|        10397|      75|      57|\n|        19|        5|     DL|          12953|        10397|      -1|      10|\n|        19|        5|     DL|          11433|        12953|      -3|     -10|\n|        19|        5|     DL|          10397|        14771|      31|      38|\n|        19|        5|     DL|          13204|        10397|       8|      25|\n+----------+---------+-------+---------------+-------------+--------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "source": [
    "Load the Airport Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=spark.read.csv(\"C:/Users/User/Desktop/SparkFolder/Data/airports.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+-----------+-----+--------------------+\n|airport_id|       city|state|                name|\n+----------+-----------+-----+--------------------+\n|     10165|Adak Island|   AK|                Adak|\n|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n|     10304|      Aniak|   AK|       Aniak Airport|\n|     10754|     Barrow|   AK|Wiley Post/Will R...|\n|     10551|     Bethel|   AK|      Bethel Airport|\n+----------+-----------+-----+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- airport_id: integer (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- name: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "source": [
    "Redefine Schema for Airports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportschema=StructType([\n",
    "\n",
    "                            StructField(\"airport_id\",IntegerType(), False),\n",
    "                            StructField(\"city\",StringType(), False),\n",
    "                            StructField(\"state\",StringType(), False),\n",
    "                            StructField(\"name\",StringType(), False)\n",
    "                            \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=spark.read.csv(\"C:/Users/User/Desktop/SparkFolder/Data/airports.csv\",schema=airportschema,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- airport_id: integer (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- name: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+-----------+-----+--------------------+\n|airport_id|       city|state|                name|\n+----------+-----------+-----+--------------------+\n|     10165|Adak Island|   AK|                Adak|\n|     10299|  Anchorage|   AK|Ted Stevens Ancho...|\n|     10304|      Aniak|   AK|       Aniak Airport|\n|     10754|     Barrow|   AK|Wiley Post/Will R...|\n|     10551|     Bethel|   AK|      Bethel Airport|\n+----------+-----------+-----+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "source": [
    "Merge the Two Data to show the flights from each city"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightbyOrigin=df1.join(df,df[\"OriginAirportID\"]==df1[\"airport_id\"]).groupBy(\"city\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+------+\n|             city| count|\n+-----------------+------+\n|          Phoenix| 90281|\n|            Omaha| 13537|\n|   Raleigh/Durham| 28436|\n|        Anchorage|  7777|\n|           Dallas| 19503|\n|          Oakland| 25503|\n|      San Antonio| 23090|\n|     Philadelphia| 47659|\n|       Louisville| 10953|\n|Dallas/Fort Worth|105024|\n|      Los Angeles|118684|\n|       Sacramento| 25193|\n|     Indianapolis| 18099|\n|        Cleveland| 25261|\n|        San Diego| 45783|\n|    San Francisco| 84675|\n|        Nashville| 34927|\n|    Oklahoma City| 13967|\n|          Detroit| 62879|\n|         Portland| 30640|\n+-----------------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "flightbyOrigin.show()"
   ]
  },
  {
   "source": [
    "Handling Duplicated Data\n",
    "* Drop duplicated and calculate duplicated Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The number of rows is : 2719418\n",
      "The number of duplicates dropped : 2696983\n",
      "The number of duplicated data : 22435\n"
     ]
    }
   ],
   "source": [
    "#Total number of rows\n",
    "n1=df.count()\n",
    "print(\"The number of rows is :\",n1)\n",
    "#Drop Duplicates\n",
    "n2=df.dropDuplicates().count()\n",
    "print(\"The number of duplicates dropped :\",n2)\n",
    "n3=n1-n2\n",
    "print(\"The number of duplicated data :\", n3)"
   ]
  },
  {
   "source": [
    "Create DataFrame from Tuples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df2=spark.createDataFrame([\n",
    "                        (\"Sol\", 54,58),\n",
    "                        (\"Sol\", 57,55),\n",
    "                        (\"Sol\", 54,58)],\n",
    "                        [\"Name\",\"age\",\"height\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2=df2.withColumn(\"ID\",monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+---+------+\n",
      "|Name|age|height|\n",
      "+----+---+------+\n",
      "| Sol| 54|    58|\n",
      "| Sol| 57|    55|\n",
      "| Sol| 54|    58|\n",
      "+----+---+------+\n",
      "\n",
      "+----+---+------+\n",
      "|Name|age|height|\n",
      "+----+---+------+\n",
      "| Sol| 54|    58|\n",
      "| Sol| 57|    55|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()\n",
    "df2.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+---+------+\n|Name|age|height|\n+----+---+------+\n| Sol| 54|    58|\n+----+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "df2.dropDuplicates([\"Name\"]).show()"
   ]
  },
  {
   "source": [
    "Handling Missing Data\n",
    "* Delete row iff there is at least one ( column) missing Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the number of missing value is 46233\n"
     ]
    }
   ],
   "source": [
    "dfmissingvalue=df.dropDuplicates().dropna(how=\"any\",subset=[\"ArrDelay\",\"DepDelay\"])\n",
    "numberofmissingvalue=n1-dfmissingvalue.count()\n",
    "print(\"the number of missing value is\", numberofmissingvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n+----------+---------+-------+---------------+-------------+--------+--------+\n|         6|        1|     WN|          10821|        10140|       1|     -22|\n|         8|        1|     AA|          11298|        10140|       0|       6|\n|        15|        1|     WN|          14747|        10140|      -6|       3|\n|        27|        1|     AA|          11298|        10140|     113|     117|\n|         7|        2|     OO|          12266|        10140|      -3|     -11|\n|        28|        2|     WN|          14107|        10140|      -3|       0|\n|        30|        2|     OO|          12266|        10140|      -4|     -11|\n|         1|        3|     EV|          12266|        10140|     -11|     -26|\n|         3|        3|     OO|          12892|        10140|      -4|      -2|\n|        17|        3|     WN|          12892|        10140|      -1|       3|\n|        22|        3|     WN|          14107|        10140|     109|     106|\n|        24|        3|     WN|          14747|        10140|       0|      -4|\n|         2|        4|     OO|          14869|        10140|      -8|     -25|\n|         4|        4|     WN|          11259|        10140|      -5|      -9|\n|         4|        4|     OO|          14771|        10140|      22|      31|\n|        11|        4|     WN|          14057|        10140|      -3|     -19|\n|         5|        5|     AA|          11298|        10140|      13|       2|\n|        12|        5|     OO|          14869|        10140|      -2|     -10|\n|         6|        6|     WN|          11259|        10140|      -3|     -10|\n|         6|        6|     WN|          12892|        10140|      -3|     -13|\n+----------+---------+-------+---------------+-------------+--------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "dfmissingvalue.show()"
   ]
  },
  {
   "source": [
    "Filling missing value with mean value of the corresponding column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------+\n|   avg(ArrDelay)|\n+----------------+\n|6.63768791455498|\n+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupby().avg(\"ArrDelay\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_arrdelay=df.groupby().avg(\"ArrDelay\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6.63768791455498"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "#Alternatively\n",
    "df.groupby().avg(\"ArrDelay\").take(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "type(df.groupby().avg(\"ArrDelay\").take(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_depdelay=df.groupby().avg(\"ArrDelay\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill missing values with mean\n",
    "flightsclean=df.fillna({\"ArrDelay\":mean_arrdelay,\"DepDelay\":mean_depdelay})\n",
    "\n"
   ]
  },
  {
   "source": [
    "Explore Stats of the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+------------------+--------+-----+--------------------+\n|summary|        airport_id|    city|state|                name|\n+-------+------------------+--------+-----+--------------------+\n|  count|               365|     365|  365|                 365|\n|   mean|12761.016438356164|    null| null|                null|\n| stddev|1660.7966378387537|    null| null|                null|\n|    min|             10135|Aberdeen|   AK|   Aberdeen Regional|\n|    max|             16440|    Yuma|   WY|Yuma MCAS/Yuma In...|\n+-------+------------------+--------+-----+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+--------+\n|ArrDelay|DepDelay|\n+--------+--------+\n|       1|      -3|\n|      -8|       0|\n|     -15|      -4|\n|      24|      28|\n|     -11|      -6|\n|     -19|      -1|\n|      -1|       0|\n|      24|      15|\n|      34|      33|\n|     322|     323|\n|     -13|      -7|\n|      41|      22|\n|      20|      40|\n|      -7|      -2|\n|      75|      71|\n|      57|      75|\n|      10|      -1|\n|     -10|      -3|\n|      38|      31|\n|      25|       8|\n+--------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "correlation=flightsclean.select(flightsclean[\"ArrDelay\"].cast(\"integer\"),\n",
    "                                flightsclean[\"DepDelay\"].cast(\"integer\"))\n",
    "correlation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "93.92984568919158 %\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    correlation.corr('ArrDelay','DepDelay') * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}